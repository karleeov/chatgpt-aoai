{"version":3,"file":"audio.js","sourceRoot":"","sources":["../../../src/models/audio.ts"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC","sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\n/**\n * THIS IS AN AUTO-GENERATED FILE - DO NOT EDIT!\n *\n * Any changes you make here may be lost.\n *\n * If you need to make changes, please do so in the original source file, \\{project-root\\}/sources/custom\n */\n\nimport { OperationOptions } from \"@azure-rest/core-client\";\n\n/** The result format of an audio task */\nexport type AudioResultFormat =\n  /** This format will return an JSON structure containing a single \\\"text\\\" with the transcription. */\n  | \"json\"\n  /** This format will return an JSON structure containing an enriched structure with the transcription. */\n  | \"verbose_json\"\n  /** This will make the response return the transcription as plain/text. */\n  | \"text\"\n  /** The transcription will be provided in SRT format (SubRip Text) in the form of plain/text. */\n  | \"srt\"\n  /** The transcription will be provided in VTT format (Web Video Text Tracks) in the form of plain/text. */\n  | \"vtt\";\n\n/** The result of an audio task in a simple JSON format */\nexport interface AudioResultSimpleJson {\n  /** Transcribed text. */\n  text: string;\n}\n\n/** Transcription response. */\nexport interface AudioResultVerboseJson extends AudioResultSimpleJson {\n  /** Audio transcription task. */\n  task: AudioTranscriptionTask;\n  /** Language detected in the source audio file. */\n  language: string;\n  /** Duration. */\n  duration: number;\n  /** Segments. */\n  segments: AudioSegment[];\n}\n\n/** Audio transcription task type */\n/** \"transcribe\", \"translate\" */\nexport type AudioTranscriptionTask = string;\n\n/** Transcription segment. */\nexport interface AudioSegment {\n  /** Segment identifier. */\n  id: number;\n  /** Segment start offset. */\n  start: number;\n  /** Segment end offset. */\n  end: number;\n  /** Segment text. */\n  text: string;\n  /** Temperature. */\n  temperature: number;\n  /** Average log probability. */\n  avgLogprob: number;\n  /** Compression ratio. */\n  compressionRatio: number;\n  /** Probability of 'no speech'. */\n  noSpeechProb: number;\n  /** Tokens in this segment */\n  tokens: number[];\n  /** TODO */\n  seek: number;\n}\n\n/** The options for an audio transcription request */\nexport interface GetAudioTranscriptionOptions extends OperationOptions {\n  /** An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language. */\n  prompt?: string;\n  /**\n   * The sampling temperature, between 0 and 1.\n   * Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n   * If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n  /** The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency. */\n  language?: string;\n  /** (non-Azure) ID of the model to use. Only whisper-1 is currently available. */\n  model?: string;\n}\n\n/** The options for an audio translation request */\nexport interface GetAudioTranslationOptions extends OperationOptions {\n  /** An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language. */\n  prompt?: string;\n  /**\n   * The sampling temperature, between 0 and 1.\n   * Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n   * If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n  /** (non-Azure) ID of the model to use. Only whisper-1 is currently available. */\n  model?: string;\n}\n\n/** The type of the result of the transcription based on the requested response format */\nexport type AudioResult<ResponseFormat extends AudioResultFormat> = {\n  json: AudioResultSimpleJson;\n  verbose_json: AudioResultVerboseJson;\n  vtt: string;\n  srt: string;\n  text: string;\n}[ResponseFormat];\n"]}