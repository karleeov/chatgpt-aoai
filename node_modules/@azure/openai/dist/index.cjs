'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

var coreAuth = require('@azure/core-auth');
var tslib = require('tslib');
var coreRestPipeline = require('@azure/core-rest-pipeline');
var formdataNode = require('formdata-node');
var node_stream = require('node:stream');
var coreClient = require('@azure-rest/core-client');
var coreSse = require('@azure/core-sse');
var coreLro = require('@azure/core-lro');
var logger$1 = require('@azure/logger');

function _interopNamespace(e) {
    if (e && e.__esModule) return e;
    var n = Object.create(null);
    if (e) {
        Object.keys(e).forEach(function (k) {
            if (k !== 'default') {
                var d = Object.getOwnPropertyDescriptor(e, k);
                Object.defineProperty(n, k, d.get ? d : {
                    enumerable: true,
                    get: function () { return e[k]; }
                });
            }
        });
    }
    n["default"] = e;
    return Object.freeze(n);
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * The OpenAIKeyCredential class represents an OpenAI API key
 * and is used to authenticate into an OpenAI client for
 * an OpenAI endpoint.
 */
class OpenAIKeyCredential {
    /**
     * Create an instance of an AzureKeyCredential for use
     * with a service client.
     *
     * @param key - The initial value of the key to use in authentication
     */
    constructor(key) {
        if (!key) {
            throw new Error("key must be a non-empty string");
        }
        this._key = createKey(key);
    }
    /**
     * The value of the key to be used in authentication
     */
    get key() {
        return this._key;
    }
    /**
     * Change the value of the key.
     *
     * Updates will take effect upon the next request after
     * updating the key value.
     *
     * @param newKey - The new key value to be used
     */
    update(newKey) {
        this._key = createKey(newKey);
    }
}
function createKey(key) {
    return key.startsWith("Bearer ") ? key : `Bearer ${key}`;
}

// Copyright (c) Microsoft Corporation.
const logger = logger$1.createClientLogger("openai");

// Copyright (c) Microsoft Corporation.
/**
 * Initialize a new instance of `OpenAIContext`
 * @param endpoint - Supported Cognitive Services endpoints (protocol and hostname, for example:
 * https://westus.api.cognitive.microsoft.com).
 * @param credentials - uniquely identify client credential
 * @param options - the parameter for all optional parameters
 */
function createClient(endpoint, credentials, options = {}) {
    var _a, _b, _c, _d, _e, _f, _g, _h;
    const baseUrl = (_a = options.baseUrl) !== null && _a !== void 0 ? _a : `${endpoint}/openai`;
    options.apiVersion = (_b = options.apiVersion) !== null && _b !== void 0 ? _b : "2023-09-01-preview";
    options = Object.assign(Object.assign({}, options), { credentials: {
            scopes: (_d = (_c = options.credentials) === null || _c === void 0 ? void 0 : _c.scopes) !== null && _d !== void 0 ? _d : ["https://cognitiveservices.azure.com/.default"],
            apiKeyHeaderName: (_f = (_e = options.credentials) === null || _e === void 0 ? void 0 : _e.apiKeyHeaderName) !== null && _f !== void 0 ? _f : "api-key",
        } });
    const userAgentInfo = `azsdk-js-openai-rest/1.0.0-beta.7`;
    const userAgentPrefix = options.userAgentOptions && options.userAgentOptions.userAgentPrefix
        ? `${options.userAgentOptions.userAgentPrefix} ${userAgentInfo}`
        : `${userAgentInfo}`;
    options = Object.assign(Object.assign({}, options), { userAgentOptions: {
            userAgentPrefix,
        }, loggingOptions: {
            logger: (_h = (_g = options.loggingOptions) === null || _g === void 0 ? void 0 : _g.logger) !== null && _h !== void 0 ? _h : logger.info,
        } });
    const client = coreClient.getClient(baseUrl, credentials, options);
    return client;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
const responseMap = {
    "POST /deployments/{deploymentId}/embeddings": ["200"],
    "POST /deployments/{deploymentId}/completions": ["200"],
    "POST /deployments/{deploymentId}/chat/completions": ["200"],
    "POST /deployments/{deploymentId}/extensions/chat/completions": ["200"],
    "GET /operations/images/{operationId}": ["200"],
    "POST /images/generations:submit": ["202"],
    "GET /images/generations:submit": ["200", "202"],
};
function isUnexpected(response) {
    const lroOriginal = response.headers["x-ms-original-url"];
    const url = new URL(lroOriginal !== null && lroOriginal !== void 0 ? lroOriginal : response.request.url);
    const method = response.request.method;
    let pathDetails = responseMap[`${method} ${url.pathname}`];
    if (!pathDetails) {
        pathDetails = getParametrizedPathSuccess(method, url.pathname);
    }
    return !pathDetails.includes(response.status);
}
function getParametrizedPathSuccess(method, path) {
    var _a, _b, _c, _d;
    const pathParts = path.split("/");
    // Traverse list to match the longest candidate
    // matchedLen: the length of candidate path
    // matchedValue: the matched status code array
    let matchedLen = -1, matchedValue = [];
    // Iterate the responseMap to find a match
    for (const [key, value] of Object.entries(responseMap)) {
        // Extracting the path from the map key which is in format
        // GET /path/foo
        if (!key.startsWith(method)) {
            continue;
        }
        const candidatePath = getPathFromMapKey(key);
        // Get each part of the url path
        const candidateParts = candidatePath.split("/");
        // track if we have found a match to return the values found.
        let found = true;
        for (let i = candidateParts.length - 1, j = pathParts.length - 1; i >= 1 && j >= 1; i--, j--) {
            if (((_a = candidateParts[i]) === null || _a === void 0 ? void 0 : _a.startsWith("{")) && ((_b = candidateParts[i]) === null || _b === void 0 ? void 0 : _b.indexOf("}")) !== -1) {
                const start = candidateParts[i].indexOf("}") + 1, end = (_c = candidateParts[i]) === null || _c === void 0 ? void 0 : _c.length;
                // If the current part of the candidate is a "template" part
                // Try to use the suffix of pattern to match the path
                // {guid} ==> $
                // {guid}:export ==> :export$
                const isMatched = new RegExp(`${(_d = candidateParts[i]) === null || _d === void 0 ? void 0 : _d.slice(start, end)}`).test(pathParts[j] || "");
                if (!isMatched) {
                    found = false;
                    break;
                }
                continue;
            }
            // If the candidate part is not a template and
            // the parts don't match mark the candidate as not found
            // to move on with the next candidate path.
            if (candidateParts[i] !== pathParts[j]) {
                found = false;
                break;
            }
        }
        // We finished evaluating the current candidate parts
        // Update the matched value if and only if we found the longer pattern
        if (found && candidatePath.length > matchedLen) {
            matchedLen = candidatePath.length;
            matchedValue = value;
        }
    }
    return matchedValue;
}
function getPathFromMapKey(mapKey) {
    const pathStart = mapKey.indexOf("/");
    return mapKey.slice(pathStart);
}

// Copyright (c) Microsoft Corporation.
async function getLongRunningPoller(client, initialResponse, options = {}) {
    var _a;
    const poller = {
        requestMethod: initialResponse.request.method,
        requestPath: initialResponse.request.url,
        sendInitialRequest: async () => {
            // In the case of Rest Clients we are building the LRO poller object from a response that's the reason
            // we are not triggering the initial request here, just extracting the information from the
            // response we were provided.
            return getLroResponse(initialResponse);
        },
        sendPollRequest: async (path) => {
            // This is the callback that is going to be called to poll the service
            // to get the latest status. We use the client provided and the polling path
            // which is an opaque URL provided by caller, the service sends this in one of the following headers: operation-location, azure-asyncoperation or location
            // depending on the lro pattern that the service implements. If non is provided we default to the initial path.
            const response = await client.pathUnchecked(path !== null && path !== void 0 ? path : initialResponse.request.url).get();
            const lroResponse = getLroResponse(response);
            lroResponse.rawResponse.headers["x-ms-original-url"] = initialResponse.request.url;
            return lroResponse;
        },
    };
    options.resolveOnUnsuccessful = (_a = options.resolveOnUnsuccessful) !== null && _a !== void 0 ? _a : true;
    return coreLro.createHttpPoller(poller, options);
}
/**
 * Converts a Rest Client response to a response that the LRO implementation understands
 * @param response - a rest client http response
 * @returns - An LRO response that the LRO implementation understands
 */
function getLroResponse(response) {
    if (Number.isNaN(response.status)) {
        throw new TypeError(`Status code of the response is not a number. Value: ${response.status}`);
    }
    return {
        flatResponse: response,
        rawResponse: Object.assign(Object.assign({}, response), { statusCode: Number.parseInt(response.status), body: response.body }),
    };
}

// Copyright (c) Microsoft Corporation.
/** Azure OpenAI APIs for completions and search */
function createOpenAI(endpoint, credential, options = {}) {
    const baseUrl = endpoint;
    const clientContext = createClient(baseUrl, credential, options);
    return clientContext;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
function getPromptFilterResult(body) {
    var _a;
    const res = (_a = body["prompt_annotations"]) !== null && _a !== void 0 ? _a : body["prompt_filter_results"];
    return !res
        ? {}
        : {
            promptFilterResults: res.map((p) => (Object.assign({ promptIndex: p["prompt_index"] }, (!p.content_filter_results
                ? {}
                : {
                    contentFilterResults: deserializeContentFilter(p.content_filter_results),
                })))),
        };
}
function getCompletionsResult(body) {
    var _a;
    return Object.assign(Object.assign({ id: body["id"], created: new Date(body["created"]) }, getPromptFilterResult(body)), { choices: ((_a = body["choices"]) !== null && _a !== void 0 ? _a : []).map((p) => (Object.assign(Object.assign({ text: p["text"], index: p["index"] }, (!p.content_filter_results
            ? {}
            : {
                contentFilterResults: deserializeContentFilter(p.content_filter_results),
            })), { logprobs: p.logprobs === null
                ? null
                : {
                    tokens: p.logprobs["tokens"],
                    tokenLogprobs: p.logprobs["token_logprobs"],
                    topLogprobs: p.logprobs["top_logprobs"],
                    textOffset: p.logprobs["text_offset"],
                }, finishReason: p["finish_reason"] }))) });
}
function getChatCompletionsResult(body) {
    var _a;
    return Object.assign(Object.assign({ id: body["id"], created: new Date(body["created"]), choices: ((_a = body["choices"]) !== null && _a !== void 0 ? _a : []).map((p) => (Object.assign(Object.assign(Object.assign(Object.assign({}, (!p.message ? {} : { message: _deserializeMessage(p.message) })), { index: p["index"], finishReason: p["finish_reason"] }), (!p.delta ? {} : { delta: _deserializeMessage(p.delta) })), (!p.content_filter_results
            ? {}
            : { contentFilterResults: deserializeContentFilter(p.content_filter_results) })))) }, getPromptFilterResult(body)), (!body["usage"]
        ? {}
        : {
            usage: {
                completionTokens: body["usage"].completion_tokens,
                promptTokens: body["usage"].prompt_tokens,
                totalTokens: body["usage"].total_tokens,
            },
        }));
}
function _deserializeMessage(message) {
    var _a, _b;
    return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({}, (!message["role"] ? {} : { role: message["role"] })), (!message["content"] ? {} : { content: message["content"] })), (!message["name"] ? {} : { name: message["name"] })), (!message.function_call
        ? {}
        : {
            functionCall: {
                name: (_a = message.function_call) === null || _a === void 0 ? void 0 : _a["name"],
                arguments: (_b = message.function_call) === null || _b === void 0 ? void 0 : _b["arguments"],
            },
        })), (!message.context
        ? {}
        : {
            context: Object.assign({}, (!message.context.messages
                ? {}
                : {
                    messages: message.context.messages.map((m) => {
                        return _deserializeMessage(m);
                    }),
                })),
        }));
}
function deserializeContentFilter(result) {
    var _a, _b, _c, _d, _e, _f, _g, _h, _j;
    if (result.error) {
        return {
            error: {
                code: result.error.code,
                message: result.error.message,
                details: (_a = result.error.details) !== null && _a !== void 0 ? _a : [],
            },
        };
    }
    return Object.assign(Object.assign(Object.assign(Object.assign({}, (!result.sexual
        ? {}
        : {
            sexual: {
                severity: (_b = result.sexual) === null || _b === void 0 ? void 0 : _b["severity"],
                filtered: (_c = result.sexual) === null || _c === void 0 ? void 0 : _c["filtered"],
            },
        })), (!result.violence
        ? {}
        : {
            violence: {
                severity: (_d = result.violence) === null || _d === void 0 ? void 0 : _d["severity"],
                filtered: (_e = result.violence) === null || _e === void 0 ? void 0 : _e["filtered"],
            },
        })), (!result.hate
        ? {}
        : {
            hate: {
                severity: (_f = result.hate) === null || _f === void 0 ? void 0 : _f["severity"],
                filtered: (_g = result.hate) === null || _g === void 0 ? void 0 : _g["filtered"],
            },
        })), (!result.self_harm
        ? {}
        : {
            selfHarm: {
                severity: (_h = result.self_harm) === null || _h === void 0 ? void 0 : _h["severity"],
                filtered: (_j = result.self_harm) === null || _j === void 0 ? void 0 : _j["filtered"],
            },
        }));
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * THIS IS AN AUTO-GENERATED FILE - DO NOT EDIT!
 *
 * Any changes you make here may be lost.
 *
 * If you need to make changes, please do so in the original source file, \{project-root\}/sources/custom
 */
function wrapError(f, message) {
    try {
        const result = f();
        return result;
    }
    catch (cause) {
        throw new Error(`${message}: ${cause}`, { cause });
    }
}
function tocamelCase(str) {
    return str.replace(/([_][a-z])/g, (group) => group.toUpperCase().replace("_", ""));
}
/**
 * Rename keys to camel case.
 * @param obj - The object to rename keys to camel case
 * @returns The object with keys renamed to camel case
 */
function renameKeysToCamelCase(obj) {
    for (const key of Object.keys(obj)) {
        const value = obj[key];
        const newKey = tocamelCase(key);
        if (newKey !== key) {
            delete obj[key];
        }
        obj[newKey] =
            typeof value === "object"
                ? Array.isArray(value)
                    ? value.map((v) => renameKeysToCamelCase(v))
                    : renameKeysToCamelCase(value)
                : value;
    }
    return obj;
}

// Copyright (c) Microsoft Corporation.
async function getSSEs(response) {
    const chunkIterator = await getStream(response);
    return coreSse.iterateSseStream(chunkIterator);
}
async function getStream(response) {
    const { body, status } = await response.asNodeStream();
    if (status !== "200" && body !== undefined) {
        const text = await streamToText(body);
        throw wrapError(() => JSON.parse(text).error, "Error parsing response body");
    }
    if (!body)
        throw new Error("No stream found in response. Did you enable the stream option?");
    return body;
}
function streamToText(stream) {
    return new Promise((resolve, reject) => {
        const buffer = [];
        stream.on("data", (chunk) => {
            if (Buffer.isBuffer(chunk)) {
                buffer.push(chunk);
            }
            else {
                buffer.push(Buffer.from(chunk));
            }
        });
        stream.on("end", () => {
            resolve(Buffer.concat(buffer).toString("utf8"));
        });
        stream.on("error", (e) => {
            if (e && (e === null || e === void 0 ? void 0 : e.name) === "AbortError") {
                reject(e);
            }
            else {
                reject(new coreRestPipeline.RestError(`Error reading response as text: ${e.message}`, {
                    code: coreRestPipeline.RestError.PARSE_ERROR,
                }));
            }
        });
    });
}

// Copyright (c) Microsoft Corporation.
function getOaiSSEs(response, toEvent) {
    return tslib.__asyncGenerator(this, arguments, function* getOaiSSEs_1() {
        var _a, e_1, _b, _c;
        const stream = yield tslib.__await(getSSEs(response));
        let isDone = false;
        try {
            for (var _d = true, stream_1 = tslib.__asyncValues(stream), stream_1_1; stream_1_1 = yield tslib.__await(stream_1.next()), _a = stream_1_1.done, !_a;) {
                _c = stream_1_1.value;
                _d = false;
                try {
                    const event = _c;
                    if (isDone) {
                        // handle a case where the service sends excess stream
                        // data after the [DONE] event
                        continue;
                    }
                    else if (event.data === "[DONE]") {
                        isDone = true;
                    }
                    else {
                        yield yield tslib.__await(toEvent(wrapError(() => JSON.parse(event.data), "Error parsing an event. See 'cause' for more details")));
                    }
                }
                finally {
                    _d = true;
                }
            }
        }
        catch (e_1_1) { e_1 = { error: e_1_1 }; }
        finally {
            try {
                if (!_d && !_a && (_b = stream_1.return)) yield tslib.__await(_b.call(stream_1));
            }
            finally { if (e_1) throw e_1.error; }
        }
    });
}

// Copyright (c) Microsoft Corporation.
/**
 * The programmatic identifier of the formDataPolicy.
 */
const formDataPolicyName = "formDataPolicyWithFileUpload";
/**
 * A policy that encodes FormData on the request into the body.
 */
function formDataWithFileUploadPolicy(boundary) {
    return {
        name: formDataPolicyName,
        async sendRequest(request, next) {
            if (request.formData) {
                const contentType = request.headers.get("Content-Type");
                if (contentType && contentType.indexOf("application/x-www-form-urlencoded") !== -1) {
                    request.body = wwwFormUrlEncode(request.formData);
                    request.formData = undefined;
                }
                else {
                    await prepareFormData(request.formData, request, boundary);
                }
            }
            return next(request);
        },
    };
}
function wwwFormUrlEncode(formData) {
    const urlSearchParams = new URLSearchParams();
    for (const [key, value] of Object.entries(formData)) {
        if (Array.isArray(value)) {
            for (const subValue of value) {
                urlSearchParams.append(key, subValue.toString());
            }
        }
        else {
            urlSearchParams.append(key, value.toString());
        }
    }
    return urlSearchParams.toString();
}
async function prepareFormData(formData, request, boundary) {
    const requestForm = new formdataNode.FormData();
    for (const formKey of Object.keys(formData)) {
        const formValue = formData[formKey];
        if (Array.isArray(formValue)) {
            for (const subValue of formValue) {
                requestForm.append(formKey, subValue);
            }
        }
        else {
            requestForm.append(formKey, formValue);
        }
    }
    // This library doesn't define `type` entries in the exports section of its package.json.
    // See https://github.com/microsoft/TypeScript/issues/52363
    const { FormDataEncoder } = await Promise.resolve().then(function () { return /*#__PURE__*/_interopNamespace(require('form-data-encoder')); });
    const encoder = boundary
        ? new FormDataEncoder(requestForm, boundary)
        : new FormDataEncoder(requestForm);
    const body = node_stream.Readable.from(encoder.encode());
    request.body = body;
    request.formData = undefined;
    const contentType = request.headers.get("Content-Type");
    if (contentType && contentType.indexOf("multipart/form-data") !== -1) {
        request.headers.set("Content-Type", encoder.contentType);
    }
    const contentLength = encoder.contentLength;
    if (contentLength !== undefined) {
        request.headers.set("Content-Length", contentLength);
    }
}
function createFile(data) {
    return new formdataNode.File([data], "placeholder.wav");
}

// Copyright (c) Microsoft Corporation.
function _getEmbeddingsSend(context, input, deploymentId, options = { requestOptions: {} }) {
    return context.path("/deployments/{deploymentId}/embeddings", deploymentId).post(Object.assign(Object.assign({}, coreClient.operationOptionsToRequestParameters(options)), { body: { user: options === null || options === void 0 ? void 0 : options.user, model: options === null || options === void 0 ? void 0 : options.model, input: input } }));
}
async function _getEmbeddingsDeserialize(result) {
    var _a;
    if (isUnexpected(result)) {
        throw result.body.error;
    }
    return {
        data: ((_a = result.body["data"]) !== null && _a !== void 0 ? _a : []).map((p) => ({
            embedding: p["embedding"],
            index: p["index"],
        })),
        usage: {
            promptTokens: result.body.usage["prompt_tokens"],
            totalTokens: result.body.usage["total_tokens"],
        },
    };
}
/** Return the embeddings for a given prompt. */
async function getEmbeddings(context, input, deploymentId, options = { requestOptions: {} }) {
    const result = await _getEmbeddingsSend(context, input, deploymentId, options);
    return _getEmbeddingsDeserialize(result);
}
function _getCompletionsSend(context, prompt, deploymentId, options = { requestOptions: {} }) {
    return context.path("/deployments/{deploymentId}/completions", deploymentId).post(Object.assign(Object.assign({}, coreClient.operationOptionsToRequestParameters(options)), { body: {
            prompt: prompt,
            max_tokens: options === null || options === void 0 ? void 0 : options.maxTokens,
            temperature: options === null || options === void 0 ? void 0 : options.temperature,
            top_p: options === null || options === void 0 ? void 0 : options.topP,
            logit_bias: options === null || options === void 0 ? void 0 : options.logitBias,
            user: options === null || options === void 0 ? void 0 : options.user,
            n: options === null || options === void 0 ? void 0 : options.n,
            logprobs: options === null || options === void 0 ? void 0 : options.logprobs,
            echo: options === null || options === void 0 ? void 0 : options.echo,
            stop: options === null || options === void 0 ? void 0 : options.stop,
            presence_penalty: options === null || options === void 0 ? void 0 : options.presencePenalty,
            frequency_penalty: options === null || options === void 0 ? void 0 : options.frequencyPenalty,
            best_of: options === null || options === void 0 ? void 0 : options.bestOf,
            stream: options === null || options === void 0 ? void 0 : options.stream,
            model: options === null || options === void 0 ? void 0 : options.model,
        } }));
}
async function _getCompletionsDeserialize(result) {
    var _a, _b;
    if (isUnexpected(result)) {
        throw result.body.error;
    }
    return {
        id: result.body["id"],
        created: new Date(result.body["created"]),
        promptFilterResults: ((_a = result.body["prompt_annotations"]) !== null && _a !== void 0 ? _a : []).map((p) => {
            var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m, _o, _p, _q, _r, _s, _t, _u, _v;
            return ({
                promptIndex: p["prompt_index"],
                contentFilterResults: !p.content_filter_results
                    ? undefined
                    : {
                        sexual: !((_a = p.content_filter_results) === null || _a === void 0 ? void 0 : _a.sexual)
                            ? undefined
                            : {
                                severity: (_c = (_b = p.content_filter_results) === null || _b === void 0 ? void 0 : _b.sexual) === null || _c === void 0 ? void 0 : _c["severity"],
                                filtered: (_e = (_d = p.content_filter_results) === null || _d === void 0 ? void 0 : _d.sexual) === null || _e === void 0 ? void 0 : _e["filtered"],
                            },
                        violence: !((_f = p.content_filter_results) === null || _f === void 0 ? void 0 : _f.violence)
                            ? undefined
                            : {
                                severity: (_h = (_g = p.content_filter_results) === null || _g === void 0 ? void 0 : _g.violence) === null || _h === void 0 ? void 0 : _h["severity"],
                                filtered: (_k = (_j = p.content_filter_results) === null || _j === void 0 ? void 0 : _j.violence) === null || _k === void 0 ? void 0 : _k["filtered"],
                            },
                        hate: !((_l = p.content_filter_results) === null || _l === void 0 ? void 0 : _l.hate)
                            ? undefined
                            : {
                                severity: (_o = (_m = p.content_filter_results) === null || _m === void 0 ? void 0 : _m.hate) === null || _o === void 0 ? void 0 : _o["severity"],
                                filtered: (_q = (_p = p.content_filter_results) === null || _p === void 0 ? void 0 : _p.hate) === null || _q === void 0 ? void 0 : _q["filtered"],
                            },
                        selfHarm: !((_r = p.content_filter_results) === null || _r === void 0 ? void 0 : _r.self_harm)
                            ? undefined
                            : {
                                severity: (_t = (_s = p.content_filter_results) === null || _s === void 0 ? void 0 : _s.self_harm) === null || _t === void 0 ? void 0 : _t["severity"],
                                filtered: (_v = (_u = p.content_filter_results) === null || _u === void 0 ? void 0 : _u.self_harm) === null || _v === void 0 ? void 0 : _v["filtered"],
                            },
                    },
            });
        }),
        choices: ((_b = result.body["choices"]) !== null && _b !== void 0 ? _b : []).map((p) => {
            var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m, _o, _p, _q, _r, _s, _t, _u, _v;
            return ({
                text: p["text"],
                index: p["index"],
                contentFilterResults: !p.content_filter_results
                    ? undefined
                    : {
                        sexual: !((_a = p.content_filter_results) === null || _a === void 0 ? void 0 : _a.sexual)
                            ? undefined
                            : {
                                severity: (_c = (_b = p.content_filter_results) === null || _b === void 0 ? void 0 : _b.sexual) === null || _c === void 0 ? void 0 : _c["severity"],
                                filtered: (_e = (_d = p.content_filter_results) === null || _d === void 0 ? void 0 : _d.sexual) === null || _e === void 0 ? void 0 : _e["filtered"],
                            },
                        violence: !((_f = p.content_filter_results) === null || _f === void 0 ? void 0 : _f.violence)
                            ? undefined
                            : {
                                severity: (_h = (_g = p.content_filter_results) === null || _g === void 0 ? void 0 : _g.violence) === null || _h === void 0 ? void 0 : _h["severity"],
                                filtered: (_k = (_j = p.content_filter_results) === null || _j === void 0 ? void 0 : _j.violence) === null || _k === void 0 ? void 0 : _k["filtered"],
                            },
                        hate: !((_l = p.content_filter_results) === null || _l === void 0 ? void 0 : _l.hate)
                            ? undefined
                            : {
                                severity: (_o = (_m = p.content_filter_results) === null || _m === void 0 ? void 0 : _m.hate) === null || _o === void 0 ? void 0 : _o["severity"],
                                filtered: (_q = (_p = p.content_filter_results) === null || _p === void 0 ? void 0 : _p.hate) === null || _q === void 0 ? void 0 : _q["filtered"],
                            },
                        selfHarm: !((_r = p.content_filter_results) === null || _r === void 0 ? void 0 : _r.self_harm)
                            ? undefined
                            : {
                                severity: (_t = (_s = p.content_filter_results) === null || _s === void 0 ? void 0 : _s.self_harm) === null || _t === void 0 ? void 0 : _t["severity"],
                                filtered: (_v = (_u = p.content_filter_results) === null || _u === void 0 ? void 0 : _u.self_harm) === null || _v === void 0 ? void 0 : _v["filtered"],
                            },
                    },
                logprobs: p.logprobs === null
                    ? null
                    : {
                        tokens: p.logprobs["tokens"],
                        tokenLogprobs: p.logprobs["token_logprobs"],
                        topLogprobs: p.logprobs["top_logprobs"],
                        textOffset: p.logprobs["text_offset"],
                    },
                finishReason: p["finish_reason"],
            });
        }),
        usage: {
            completionTokens: result.body.usage["completion_tokens"],
            promptTokens: result.body.usage["prompt_tokens"],
            totalTokens: result.body.usage["total_tokens"],
        },
    };
}
/**
 * Gets completions for the provided input prompts.
 * Completions support a wide variety of tasks and generate text that continues from or "completes"
 * provided prompt data.
 */
async function getCompletions(context, prompt, deploymentId, options = { requestOptions: {} }) {
    const result = await _getCompletionsSend(context, prompt, deploymentId, options);
    return _getCompletionsDeserialize(result);
}
function _getChatCompletionsSend(context, messages, deploymentId, options = { requestOptions: {} }) {
    return context.path("/deployments/{deploymentId}/chat/completions", deploymentId).post(Object.assign(Object.assign({}, coreClient.operationOptionsToRequestParameters(options)), { body: {
            messages: parseChatMessage(messages),
            functions: options === null || options === void 0 ? void 0 : options.functions,
            function_call: options === null || options === void 0 ? void 0 : options.functionCall,
            max_tokens: options === null || options === void 0 ? void 0 : options.maxTokens,
            temperature: options === null || options === void 0 ? void 0 : options.temperature,
            top_p: options === null || options === void 0 ? void 0 : options.topP,
            logit_bias: options === null || options === void 0 ? void 0 : options.logitBias,
            user: options === null || options === void 0 ? void 0 : options.user,
            n: options === null || options === void 0 ? void 0 : options.n,
            stop: options === null || options === void 0 ? void 0 : options.stop,
            presence_penalty: options === null || options === void 0 ? void 0 : options.presencePenalty,
            frequency_penalty: options === null || options === void 0 ? void 0 : options.frequencyPenalty,
            stream: options === null || options === void 0 ? void 0 : options.stream,
            model: options === null || options === void 0 ? void 0 : options.model,
            dataSources: options === null || options === void 0 ? void 0 : options.dataSources,
        } }));
}
function _getChatCompletionsWithAzureExtensionsSend(context, messages, deploymentId, options = { requestOptions: {} }) {
    return context
        .path("/deployments/{deploymentId}/extensions/chat/completions", deploymentId)
        .post(Object.assign(Object.assign({}, coreClient.operationOptionsToRequestParameters(options)), { body: {
            messages: parseChatMessage(messages),
            functions: options === null || options === void 0 ? void 0 : options.functions,
            function_call: options === null || options === void 0 ? void 0 : options.functionCall,
            max_tokens: options === null || options === void 0 ? void 0 : options.maxTokens,
            temperature: options === null || options === void 0 ? void 0 : options.temperature,
            top_p: options === null || options === void 0 ? void 0 : options.topP,
            logit_bias: options === null || options === void 0 ? void 0 : options.logitBias,
            user: options === null || options === void 0 ? void 0 : options.user,
            n: options === null || options === void 0 ? void 0 : options.n,
            stop: options === null || options === void 0 ? void 0 : options.stop,
            presence_penalty: options === null || options === void 0 ? void 0 : options.presencePenalty,
            frequency_penalty: options === null || options === void 0 ? void 0 : options.frequencyPenalty,
            stream: options === null || options === void 0 ? void 0 : options.stream,
            model: options === null || options === void 0 ? void 0 : options.model,
            dataSources: options === null || options === void 0 ? void 0 : options.dataSources,
        } }));
}
function _beginAzureBatchImageGenerationSend(context, prompt, options = { requestOptions: {} }) {
    return context.path("/images/generations:submit").post(Object.assign(Object.assign({}, coreClient.operationOptionsToRequestParameters(options)), { body: {
            prompt: prompt,
            n: options === null || options === void 0 ? void 0 : options.n,
            size: options === null || options === void 0 ? void 0 : options.size,
            response_format: options === null || options === void 0 ? void 0 : options.responseFormat,
            user: options === null || options === void 0 ? void 0 : options.user,
        } }));
}
function listCompletions(context, prompt, deploymentName, options = { requestOptions: {} }) {
    const response = _getCompletionsSend(context, prompt, deploymentName, Object.assign(Object.assign({}, options), { stream: true }));
    return getOaiSSEs(response, getCompletionsResult);
}
async function getImages(context, prompt, options = { requestOptions: {} }) {
    const response = await _beginAzureBatchImageGenerationSend(context, prompt, options);
    if (isUnexpected(response)) {
        // Check for response from OpenAI
        const body = response.body;
        if (body.created && body.data) {
            return body;
        }
        throw response.body.error;
    }
    if (response.status === "202") {
        const poller = await getLongRunningPoller(context, response);
        const result = await poller.pollUntilDone();
        return getImageResultsDeserialize(result);
    }
    else {
        return getImageResultsDeserialize(response);
    }
}
function listChatCompletions(context, messages, deploymentName, options = { requestOptions: {} }) {
    const response = _getChatCompletionsSendX(context, messages, deploymentName, Object.assign(Object.assign({}, options), { stream: true }));
    return getOaiSSEs(response, getChatCompletionsResult);
}
/**
 * Gets chat completions for the provided chat messages.
 * Completions support a wide variety of tasks and generate text that continues from or "completes"
 * provided prompt data.
 */
async function getChatCompletions(context, messages, deploymentId, options = { requestOptions: {} }) {
    const result = await _getChatCompletionsSendX(context, messages, deploymentId, options);
    if (isUnexpected(result)) {
        throw result.body.error;
    }
    return getChatCompletionsResult(result.body);
}
function convertResultTypes({ created, data }) {
    if (typeof data[0].url === "string") {
        return {
            created: new Date(created),
            data: data,
        };
    }
    else {
        return {
            created: new Date(created),
            data: data.map((item) => {
                return {
                    base64Data: item.b64_json,
                };
            }),
        };
    }
}
function getImageResultsDeserialize(response) {
    if (isUnexpected(response) || !response.body.result) {
        throw response.body.error;
    }
    const result = response.body.result;
    return convertResultTypes(result);
}
function _getChatCompletionsSendX(context, messages, deploymentName, options = { requestOptions: {} }) {
    var _a, _b;
    return ((_a = options.azureExtensionOptions) === null || _a === void 0 ? void 0 : _a.extensions)
        ? _getChatCompletionsWithAzureExtensionsSend(context, messages, deploymentName, Object.assign(Object.assign({}, options), { dataSources: (_b = options.azureExtensionOptions) === null || _b === void 0 ? void 0 : _b.extensions }))
        : _getChatCompletionsSend(context, messages, deploymentName, options);
}
// implementation
async function getAudioTranslation(context, deploymentName, fileContent, formatOrOptions, inputOptions) {
    const options = inputOptions !== null && inputOptions !== void 0 ? inputOptions : (typeof formatOrOptions === "string" ? {} : formatOrOptions !== null && formatOrOptions !== void 0 ? formatOrOptions : {});
    const response_format = typeof formatOrOptions === "string" ? formatOrOptions : undefined;
    const { temperature, prompt, model } = options, rest = tslib.__rest(options, ["temperature", "prompt", "model"]);
    const { body, status } = await context
        .pathUnchecked("deployments/{deploymentId}/audio/translations", deploymentName)
        .post(Object.assign(Object.assign({ body: Object.assign(Object.assign(Object.assign(Object.assign({ file: createFile(fileContent) }, (response_format && { response_format })), (temperature !== undefined ? { temperature } : {})), (prompt && { prompt })), (model && { model })) }, rest), { contentType: "multipart/form-data" }));
    if (status !== "200") {
        throw body.error;
    }
    return response_format !== "verbose_json"
        ? body
        : renameKeysToCamelCase(body);
}
// implementation
async function getAudioTranscription(context, deploymentName, fileContent, formatOrOptions, inputOptions) {
    const options = inputOptions !== null && inputOptions !== void 0 ? inputOptions : (typeof formatOrOptions === "string" ? {} : formatOrOptions !== null && formatOrOptions !== void 0 ? formatOrOptions : {});
    const response_format = typeof formatOrOptions === "string" ? formatOrOptions : undefined;
    const { temperature, language, prompt, model } = options, rest = tslib.__rest(options, ["temperature", "language", "prompt", "model"]);
    const { body, status } = await context
        .pathUnchecked("deployments/{deploymentId}/audio/transcriptions", deploymentName)
        .post(Object.assign(Object.assign({ body: Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({ file: createFile(fileContent) }, (response_format && { response_format })), (language && { language })), (temperature !== undefined ? { temperature } : {})), (prompt && { prompt })), (model && { model })) }, rest), { contentType: "multipart/form-data" }));
    if (status !== "200") {
        throw body.error;
    }
    return response_format !== "verbose_json"
        ? body
        : renameKeysToCamelCase(body);
}
function parseChatMessage(messages) {
    return messages.map((p) => {
        var _a;
        return ({
            role: p.role,
            content: (_a = p.content) !== null && _a !== void 0 ? _a : null,
            name: p.name,
            function_call: p.functionCall,
            context: p.context,
        });
    });
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
function nonAzurePolicy() {
    const policy = {
        name: "openAiEndpoint",
        sendRequest: (request, next) => {
            const obj = new URL(request.url);
            const parts = obj.pathname.split("/");
            switch (parts[parts.length - 1]) {
                case "completions":
                    if (parts[parts.length - 2] === "chat") {
                        obj.pathname = `${parts[1]}/chat/completions`;
                    }
                    else {
                        obj.pathname = `${parts[1]}/completions`;
                    }
                    break;
                case "embeddings":
                    obj.pathname = `${parts[1]}/embeddings`;
                    break;
                case "generations:submit":
                    obj.pathname = `${parts[1]}/images/generations`;
                    break;
                case "transcriptions":
                    obj.pathname = `${parts[1]}/audio/transcriptions`;
                    break;
                case "translations":
                    obj.pathname = `${parts[1]}/audio/translations`;
                    break;
            }
            obj.searchParams.delete("api-version");
            request.url = obj.toString();
            return next(request);
        },
    };
    return policy;
}

// Copyright (c) Microsoft Corporation.
class OpenAIClient {
    constructor(endpointOrOpenAiKey, credOrOptions = {}, options = {}) {
        var _a, _b;
        this._isAzure = false;
        let opts;
        let endpoint;
        let cred;
        if (isCred(credOrOptions)) {
            endpoint = endpointOrOpenAiKey;
            cred = credOrOptions;
            opts = options;
            this._isAzure = true;
        }
        else {
            endpoint = createOpenAIEndpoint(1);
            cred = endpointOrOpenAiKey;
            const { credentials } = credOrOptions, restOpts = tslib.__rest(credOrOptions, ["credentials"]);
            opts = Object.assign({ credentials: {
                    apiKeyHeaderName: (_a = credentials === null || credentials === void 0 ? void 0 : credentials.apiKeyHeaderName) !== null && _a !== void 0 ? _a : "Authorization",
                    scopes: credentials === null || credentials === void 0 ? void 0 : credentials.scopes,
                } }, restOpts);
        }
        this._client = createOpenAI(endpoint, cred, Object.assign(Object.assign({}, opts), (this._isAzure
            ? {}
            : {
                additionalPolicies: [
                    ...((_b = opts.additionalPolicies) !== null && _b !== void 0 ? _b : []),
                    {
                        position: "perCall",
                        policy: nonAzurePolicy(),
                    },
                ],
            })));
        this._client.pipeline.removePolicy({ name: coreRestPipeline.formDataPolicyName });
        this._client.pipeline.addPolicy(formDataWithFileUploadPolicy());
    }
    /**
     * Returns textual completions as configured for a given prompt.
     * @param deploymentName - Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this completions request.
     * @returns The completions for the given prompt.
     */
    getCompletions(deploymentName, prompt, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return getCompletions(this._client, prompt, deploymentName, options);
    }
    /**
     * Lists the completions tokens as they become available for a given prompt.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The completions options for this completions request.
     * @returns An asynchronous iterable of completions tokens.
     */
    listCompletions(deploymentName, prompt, options = {}) {
        this.setModel(deploymentName, options);
        return listCompletions(this._client, prompt, deploymentName, options);
    }
    /**
     * Return the computed embeddings for a given prompt.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param input - The prompt to use for this request.
     * @param options - The embeddings options for this embeddings request.
     * @returns The embeddings for the given prompt.
     */
    getEmbeddings(deploymentName, input, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return getEmbeddings(this._client, input, deploymentName, options);
    }
    /**
     * Get chat completions for provided chat context messages.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this completions request.
     * @returns The chat completions for the given chat context messages.
     */
    getChatCompletions(deploymentName, messages, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return getChatCompletions(this._client, messages, deploymentName, options);
    }
    /**
     * Lists the chat completions tokens as they become available for a chat context.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this chat completions request.
     * @returns An asynchronous iterable of chat completions tokens.
     */
    listChatCompletions(deploymentName, messages, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return listChatCompletions(this._client, messages, deploymentName, options);
    }
    /**
     * Starts the generation of a batch of images from a text caption
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this image request.
     * @returns The image generation response (containing url or base64 data).
     */
    getImages(prompt, options = { requestOptions: {} }) {
        return getImages(this._client, prompt, options);
    }
    // implementation
    async getAudioTranscription(deploymentName, fileContent, formatOrOptions, inputOptions) {
        const options = inputOptions !== null && inputOptions !== void 0 ? inputOptions : (typeof formatOrOptions === "string" ? {} : formatOrOptions !== null && formatOrOptions !== void 0 ? formatOrOptions : {});
        const response_format = typeof formatOrOptions === "string" ? formatOrOptions : undefined;
        this.setModel(deploymentName, options);
        if (response_format === undefined) {
            return getAudioTranscription(this._client, deploymentName, fileContent, options);
        }
        return getAudioTranscription(this._client, deploymentName, fileContent, response_format, options);
    }
    // implementation
    async getAudioTranslation(deploymentName, fileContent, formatOrOptions, inputOptions) {
        const options = inputOptions !== null && inputOptions !== void 0 ? inputOptions : (typeof formatOrOptions === "string" ? {} : formatOrOptions !== null && formatOrOptions !== void 0 ? formatOrOptions : {});
        const response_format = typeof formatOrOptions === "string" ? formatOrOptions : undefined;
        this.setModel(deploymentName, options);
        if (response_format === undefined) {
            return getAudioTranslation(this._client, deploymentName, fileContent, options);
        }
        return getAudioTranslation(this._client, deploymentName, fileContent, response_format, options);
    }
    setModel(model, options) {
        if (!this._isAzure) {
            options.model = model;
        }
    }
}
function createOpenAIEndpoint(version) {
    return `https://api.openai.com/v${version}`;
}
function isCred(cred) {
    return coreAuth.isTokenCredential(cred) || cred.key !== undefined;
}

Object.defineProperty(exports, 'AzureKeyCredential', {
    enumerable: true,
    get: function () { return coreAuth.AzureKeyCredential; }
});
exports.OpenAIClient = OpenAIClient;
exports.OpenAIKeyCredential = OpenAIKeyCredential;
//# sourceMappingURL=index.cjs.map
